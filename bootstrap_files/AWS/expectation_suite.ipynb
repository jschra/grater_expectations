{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Suite\n",
    "### Introduction\n",
    "In order to validate your data, Great Expectations is a package that offers a battery-included set of logic to get up-and-running fast. Fully figuring out how Great Expectations works and applying it to your project, however, can be somewhat involved. This is what Grater Expectations helps you with!\n",
    "\n",
    "This bootstrapped project makes a few choices for you and offers scripts, configurations and notebooks to get you started. The choices that were made are:\n",
    "\n",
    "- Great Expectations output will be stored on S3\n",
    "- The rendered Data Docs site will be stored on S3\n",
    "- You will write your own data loading logic to read data into memory as a pandas DataFrame\n",
    "- You will write your own set of expectations to test the quality of this data\n",
    "- The validation logic will be deployed as Docker container via AWS Lambda\n",
    "\n",
    "To set you up for the above, the `testing_config.yml` configuration file had you enter parameters that will be used throughout this project. Assuming these were properly set, you can now continue to set up your expectation suite!\n",
    "\n",
    "### Description\n",
    "This notebook can be used to generate a so-called expectation suite that can be used to run validations against your data. An expectation suite is Great Expectations jargon for a collection of expectations (or tests) that you want to run your data against. \n",
    "\n",
    "This notebook helps you to set up such a set of expectations, by loading a batch of data and writing expectations that can be run on it. After doing so, this set of expectations will be saved as an expectation suite for later usage.\n",
    "\n",
    "In the last step, this expectation suite will be connected to a checkpoint, which is an object that can be called by data validation logic to run new data batches against. Hence, after setting up an expectation suite and checkpoint using this notebook, the next step is to finalize the AWS lambda function found in `lambda_function.py` and deploy that on AWS as a Docker image. To assist with these steps Terraform configurations, a Dockerfile and a bash script (`build_image_store_on_ecr.sh`) were automatically generated.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "#### Virtual environment\n",
    "In order to run the logic contained within this notebook, make sure that it was started up from a virtual environment that contained all required Python dependencies. The easiest way to assure this is to first make a virtual environment for the project and then install `grater_expectations` within it.\n",
    "\n",
    "To create a new virtual environment, e.g. for python 3.8, and installing the package and its dependencies, run the following:\n",
    "\n",
    "<br>\n",
    "\n",
    "**Option 1: Pip**\n",
    "\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "python -m venv env\n",
    "\n",
    "# Activate the virtual environment\n",
    "env/Scripts/Activate # Windows\n",
    "source env/bin/activate # MacOS\n",
    "\n",
    "# Install into the virtual envirpnment\n",
    "pip install grater_expectations\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Option 2 - Anaconda**\n",
    "\n",
    "```bash\n",
    "# Create a conda environment\n",
    "conda create --name grater_expectations python=3.8\n",
    "\n",
    "# Activate the conda environment\n",
    "conda activate grater_expectations\n",
    "\n",
    "# Install into the virtual environment\n",
    "conda install grater_expectations\n",
    "```\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### S3 buckets\n",
    "For testing, Great Expectations is configured to interact with S3 buckets on AWS. To be able to run all the code in this notebook the **store_bucket** and **site_bucket** as configured in the testing_config.yml must be provisioned.\n",
    "\n",
    "To do so, auto-generated Terraform files can be found in the *terraform/buckets* directory of this project. To use these configurations to generate S3 buckets, open a terminal in this directory and run the following commands:\n",
    "\n",
    "<br>\n",
    "\n",
    "```bash\n",
    "# Initialize Terraform\n",
    "terraform init\n",
    "\n",
    "# Generate deployment plan, enter yes at the prompt if the plan is correct\n",
    "terraform apply\n",
    "```\n",
    "<br>\n",
    "\n",
    "**NOTE**: the code for provisioning an S3 bucket to store data in is commented out by default, assuming that a storage location with data already exists. If, however, you do want to provision an S3 bucket to store data in, comment out the configurations found in `terraform/buckets/data_bucket.tf` and run the Terraform commands shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and configurations\n",
    "In the cell below, packages are imported and configurations are loaded from the `project_config.yml` file. This config file was automatically generated by `initialize_project.py` based on the parameters set in `testing_config.yml` at the root of this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import great_expectations as ge\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "import boto3\n",
    "from supporting_functions import (TestingConfiguration, \n",
    "                                  checkpoint_without_datadocs_update, \n",
    "                                  print_ge_site_link)\n",
    "import os\n",
    "\n",
    "# Load parameters from configuration file\n",
    "test_config = TestingConfiguration(\"project_config.yml\")\n",
    "test_config.load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization of objects\n",
    "Next, objects required to interact with AWS from Python and a Great Expectations DataContext are initialized.\n",
    "\n",
    "By loading the GE configuration file (`great_expectations.yml` found in the great_expectations subdirectory of this project. The DataContext class defaults to this location and file when called), the `DataContext` object stores important parameters for you to interact with GE and automatically interact with S3 buckets for storing output, pulling checkpoints and generating Data Docs sites. For more information on data contexts, check out [the documentation](https://docs.greatexpectations.io/docs/terms/data_context/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 1. Initialize GE and S3 objects\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket = boto3.resource(\"s3\").Bucket(test_config.data_bucket)\n",
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data\n",
    "Next, logic must be written to load data. The easiest way to do so is to write a new function for this that you store in `supporting_functions.py`, so that it can be used both in this notebook and in the Lambda function.\n",
    "\n",
    "If you have your data locally as a CSV file, such a function could be as simple as:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    df_batch = pd.read_csv(path)\n",
    "\n",
    "    return df_batch\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "However, note that if you transfer this logic to a Lambda function, data will most probably have to be downloaded from another location, for example an S3 bucket. Loading logic for such a case could look like:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "def load_csv_from_s3(\n",
    "    s3_bucket_client: boto3.resource(\"s3\").Bucket, file_key: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Function that loads a csv from S3 into a pandas DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3_bucket_client : boto3.resource\n",
    "        Instantiated s3 bucket client using boto3. Note that it should already\n",
    "        be pointing to the bucket from which you want to load objects\n",
    "    file_key : str\n",
    "        Key to the channel within the tile to be loaded\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded data as pandas DataFrame\n",
    "    \"\"\"\n",
    "    s3_object = s3_bucket_client.Object(file_key).get()\n",
    "    df_batch = pd.read_csv(s3_object['Body'])\n",
    "\n",
    "    return df_batch\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Pay special attention to what inputs this function needs and how it knows what file to load, since this will need to be used in the Lambda as well. If you are able to pass the path to the file during runtime when using a Lambda (e.g. in the event sent to it), you can simply use that as a parameter of the function.\n",
    "\n",
    "Apart from the dataset, Great Expectations needs some additional parameters for operations down the line. These are an identifier for the batch being run and a name for the data asset. These can be the same, as long as they can be used to identify which dataset is being evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 2. Load data, generate asset name and batch identifier\n",
    "#\n",
    "# To generate a testing suite, a batch of data can be used to develop\n",
    "# validations. Accordingly, in the lines below custom logic is required to load\n",
    "# a test dataset as a pandas DataFrame in the df_batch argument\n",
    "#\n",
    "# To make the RuntimeBatchRequest complete, which is used by GE for the\n",
    "# validations, an asset_name and batch_identifier are required\n",
    "df_batch = load_data()  # Needs to be defined!\n",
    "batch_identifier = \"BATCH IDENTIFIER OR LOGIC TO GENERATE IT GOES HERE\"\n",
    "asset_name = \"ASSET NAME OR LOGIC TO GENERATE IT GOES HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate batch request, generate suite and start validator\n",
    "When you have succesfully written logic to load data, the loaded batch will be passed to a RuntimeBatchRequest below in order to start an expectation suite. Great Expectations requires data to be passed as a request when you want to use the context to generate things such as expectation suites and checkpoints. The RuntimeBatchRequest is used here, because we are loading data (with our own logic) at runtime and want to pass that to subsequent objects.\n",
    "\n",
    "More information on runtime batch requests can be found [here](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_configure_a_runtimedataconnector/).\n",
    "\n",
    "Using the RuntimeBatchRequest, two things are done next:\n",
    "1. Generating an expectation suite: this will serve as a collection of tests you will run for future datasets\n",
    "2. Generate a validator: this object will use the batch dataset loaded previously to start running expectations over and storing these in the suite\n",
    "\n",
    "As soon as the suite and validator are initiated, you can start writing expectations in the next cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 3. Generate batch request at runtime using loaded tile\n",
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=\"runtime_data\",\n",
    "    data_connector_name=\"runtime_data_connector\",\n",
    "    data_asset_name=asset_name,\n",
    "    runtime_parameters={\"batch_data\": df_batch},\n",
    "    batch_identifiers={\"batch_identifier\": batch_identifier,},\n",
    ")\n",
    "\n",
    "# -- 4. Generate expectation suite, start validator\n",
    "suite = context.create_expectation_suite(\n",
    "    test_config.expectations_suite_name,\n",
    "    overwrite_existing=True,  \n",
    ")\n",
    "\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=test_config.expectations_suite_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectations\n",
    "Using the validator object, expectations can be formulated below. Since Great Expectations comes with many expectations out of the box, [this page](https://greatexpectations.io/expectations) is generally a good place to start browsing through these. \n",
    "\n",
    "Predefined expectations can be used by calling them using the validator object and passing the required arguments. For example, to run an expectation on the number of rows in a dataframe, the following snippet can be used:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Get number of rows of current batch\n",
    "row_count = df_batch.shape[0]\n",
    "\n",
    "# Make expectation where the maximum deviation from the batch number of rows is 1%\n",
    "max_delta = 0.01\n",
    "validator.expect_table_row_count_to_be_between(\n",
    "    min_value=row_count * (1-max_delta), max_value=row_count * (1+max_delta))\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "If you want to develop custom expectations, more information can be found about there [here](https://docs.greatexpectations.io/docs/guides/expectations/creating_custom_expectations/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 5. Set expectations\n",
    "## PUT YOUR EXPECTATIONS BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize suite and create checkpoint\n",
    "After running all the expectations that you want to apply to the data, the cell below can be executed to save the set of expectations as a suite and couple it with a checkpoint. This checkpoint can be used in other scripts (lambda_function.py) by passing a new batch of data (as RuntimeBatchRequest) along with the checkpoint name to the `run_checkpoint` method of an initialized DataContext (which is the same as the `context` object initialized in this notebook). Such a call would look like:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "results = context.run_checkpoint(\n",
    "    checkpoint_name=\"CHECKPOINT_NAME\",\n",
    "    validations=[{\"batch_request\": batch_request}],\n",
    "    )\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE**: you should choose what kind of checkpoint you want to use below: one with or without automatic Data Docs updates\n",
    "\n",
    "When the code below is ran, Great Expectations automatically saves the expectation suite and checkpoint to S3 via the validator and context objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 6. Save suite\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "# -- 7. Create checkpoint\n",
    "#       Two options are provided here for creating a checkpoint: \n",
    "#       1. Use a SimpleCheckpoint, which contains an action to automatically update the\n",
    "#          Data Docs website whenever a validation is run\n",
    "#       2. Use checkpoint_without_datadocs_update, which generates the same\n",
    "#          SimpleCheckpoint but without an automatic Data Docs update action. This is\n",
    "#          useful if you run many validations (1000+) in parallel, since rendering the\n",
    "#          Data Docs website becomes very slow in that case          \n",
    "\n",
    "# -- 7.1 Create Simple checkpoint with automatic data docs updates (DEFAULT)\n",
    "checkpoint_config = {\n",
    "    \"name\": test_config.checkpoint_name,\n",
    "    \"config_version\": 3,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"expectation_suite_name\": test_config.expectations_suite_name,\n",
    "    \"run_name_template\": test_config.run_name_template,\n",
    "}\n",
    "\n",
    "# -- 7.2 Create checkpoint without automatic data docs update\n",
    "# checkpoint_config = checkpoint_without_datadocs_update(test_config)\n",
    "context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Data Docs website\n",
    "Next, the command below can be ran to build the Data Docs website on S3, which provides an interactive user interface in which you can browse through expectation suites and check validation results. More on Data Docs can be found [here](https://docs.greatexpectations.io/docs/reference/data_docs/)\n",
    "\n",
    "In general, if you generate the website once, new validations should automatically be loaded onto it. If the website start lagging behind, just rerun the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_site_output = context.build_data_docs()\n",
    "print_ge_site_link(ge_site_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "After you have run all of the steps above, instantiated a Data Docs website and can see your expectation suite there, you are ready to proceed with developing the logic for the Lambda function in `lambda_function.py`, creating a Docker Image with that, uploading that to ECR and deploying it as a Lambda function.\n",
    "\n",
    "Please refer to the README for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Jupyter server\n",
    "After running all commands above and generating an expectation suite, checkpoint and website, run the command below to stop the Jupyter server from running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"jupyter notebook stop\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
