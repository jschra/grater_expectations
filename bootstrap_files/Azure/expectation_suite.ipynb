{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Suite\n",
    "### Introduction\n",
    "In order to validate your data, Great Expectations is a package that offers a battery-included set of logic to get up-and-running fast. Fully figuring out how Great Expectations works and applying it to your project, however, can be somewhat involved. This is what Grater Expectations and this tutorial help you with!\n",
    "\n",
    "Grater Expectations makes a few choices for you and offers scripts, configurations and notebooks to get you started. The choices that were made are:\n",
    "\n",
    "- Great Expectations output will be stored on Azure Blob storage\n",
    "- The rendered Data Docs site will be stored on Azure Blob storage (hosted as static website)\n",
    "- You will write your own data loading logic to read data into memory as a pandas DataFrame\n",
    "- You will write your own set of expectations to test the quality of this data\n",
    "- The validation logic will be deployed as Docker container via an Azure function\n",
    "\n",
    "To set you up for the above, you already entered configurations in `testing_config.yml` for the tutorial, which will be used throughout the code to generate AWS services and access them.\n",
    "\n",
    "### Description\n",
    "This notebook can be used to generate a so-called expectation suite that can be used to run validations against your data. An expectation suite is Great Expectations jargon for a collection of expectations (or tests) that you want to run your data against. \n",
    "\n",
    "This notebook helps you to set up such a set of expectations, by loading a batch of data and writing expectations that can be run on it. After doing so, this set of expectations will be saved as an expectation suite for later usage.\n",
    "\n",
    "In the last step, this expectation suite will be connected to a checkpoint, which is an object that can be called by data validation logic to run new data batches against. Hence, after setting up an expectation suite and checkpoint using this notebook, the next step is to finalize the Azure Function function found in `function/grater-expectations/function.py` and deploy that on Azure as a Docker image. To assist with these steps Terraform configurations, a Dockerfile and a bash script (`build_image_store_on_acr.sh`) were automatically generated.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "#### Virtual environment\n",
    "In order to run the logic contained within this notebook, make sure that it was started up from a virtual environment that contained all required Python dependencies. The easiest way to assure this is to first make a virtual environment for the project and then install `grater_expectations` within it.\n",
    "\n",
    "To create a new virtual environment, e.g. for python 3.8, and installing the package and its dependencies, run the following:\n",
    "\n",
    "<br>\n",
    "\n",
    "**Option 1: Pip**\n",
    "\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "python -m venv env\n",
    "\n",
    "# Activate the virtual environment\n",
    "env/Scripts/Activate # Windows\n",
    "source env/bin/activate # MacOS\n",
    "\n",
    "# Install into the virtual envirpnment\n",
    "pip install grater_expectations\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Option 2 - Anaconda**\n",
    "\n",
    "```bash\n",
    "# Create a conda environment\n",
    "conda create --name grater_expectations python=3.8\n",
    "\n",
    "# Activate the conda environment\n",
    "conda activate grater_expectations\n",
    "\n",
    "# Install into the virtual environment\n",
    "conda install grater_expectations\n",
    "```\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Provisioning storage\n",
    "For testing, Grater Expectations is configured to interact with containers in a storage account on AWS. To be able to run all the code in this notebook the **storage_account** and **data_container_name** as configured in the testing_config.yml must be provisioned, along with the **resource_group_name** that will be provisioned to deploy services in.\n",
    "\n",
    "To do so, auto-generated Terraform files can be found in the *terraform/storage* directory of this project. To use these configurations to generate storage in that directory, open a (Git bash) terminal (if you didn't already do so), set your Azure programmatic access credentials as environment variables and run the following commands:\n",
    "\n",
    "<br>\n",
    "\n",
    "```bash\n",
    "# Set credentials\n",
    "export ARM_CLIENT_ID=\"<enter_client_id_here>\"\n",
    "export ARM_CLIENT_SECRET=\"<enter_client_secret_here>\"\n",
    "export ARM_SUBSCRIPTION_ID=\"<enter_subscription_id_here>\"\n",
    "export ARM_TENANT_ID=\"<enter_tenant_id_here>\"\n",
    "\n",
    "# Go to correct Terraform directory\n",
    "cd terraform/storage\n",
    "\n",
    "# Initialize Terraform\n",
    "terraform init\n",
    "\n",
    "# Generate deployment plan, enter yes at the prompt if the plan is correct\n",
    "terraform apply\n",
    "```\n",
    "<br>\n",
    "\n",
    "**NOTE**: the code for provisioning a container to store data in is commented out by default, assuming that a storage location with data already exists. If, however, you do want to provision a container to store data in, comment out the configurations found in `terraform/storage/data_container.tf` and run the Terraform commands shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and configurations\n",
    "In the cell below, packages are imported and configurations are loaded from the `project_config.yml` file. This config file was automatically generated by `initialize_project.py` based on the parameters set in `testing_config.yml` at the root of this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of Python and Grater Expectations packages and logic\n",
    "import great_expectations as ge\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.storage import StorageManagementClient \n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "from supporting_functions import (TestingConfiguration,\n",
    "                                  copy_tf_env_vars_for_az,\n",
    "                                  get_connection_string,\n",
    "                                  add_connection_string_to_config,\n",
    "                                  print_ge_site_link,\n",
    "                                  generate_link_in_notebook,\n",
    "                                  get_file_keys_from_container)\n",
    "from supporting_functions import load_csv_from_container as load_data\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "# -- Copy environment variables to Azure equivalents for python SDK\n",
    "copy_tf_env_vars_for_az()\n",
    "\n",
    "# -- Load parameters from configuration file\n",
    "test_config = TestingConfiguration(\"project_config.yml\")\n",
    "test_config.load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access data in the storage account, below credentials are retrieved and an object is initialized. Using this object, a connection string is retrieved for the storage account, so that it can be used in the Great Expectations configuration file to establish connections.\n",
    "\n",
    "After running the cell below, you can evaluate this by checking out the `great_expectations/great_expectations.yml` file and check if it now contains connection strings throughout the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Obtain Azure credentials, initialize storage client\n",
    "credentials = DefaultAzureCredential()\n",
    "storage_client = StorageManagementClient(credentials, os.environ.get(\"AZURE_SUBSCRIPTION_ID\"))\n",
    "\n",
    "# -- Add connection string of storage account to GE config\n",
    "connection_string = get_connection_string(storage_client, test_config)\n",
    "add_connection_string_to_config(connection_string, test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization of objects\n",
    "Next a Great Expectations DataContext is initialized.\n",
    "\n",
    "By loading the GE configuration file (`great_expectations.yml` found in the great_expectations subdirectory of this project. The DataContext class defaults to this location and file when called), the `DataContext` object stores important parameters for you to interact with GE and automatically interact with S3 buckets for storing output, pulling checkpoints and generating Data Docs sites. For more information on data contexts, check out [the documentation](https://docs.greatexpectations.io/docs/terms/data_context/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 1. Initialize GE and S3 objects\n",
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data\n",
    "Next, logic must be written to load data. The easiest way to do so is to write a new function for this that you store in `supporting_functions.py`, so that it can be used both in this notebook and in the Lambda function.\n",
    "\n",
    "If you have your data locally as a CSV file, such a function could be as simple as:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    df_batch = pd.read_csv(path)\n",
    "\n",
    "    return df_batch\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "However, note that if you transfer this logic to an Azure function, data will most probably have to be downloaded from another location, for example a storage container. Loading logic for such a case could look like:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "def load_csv_from_container(\n",
    "    blob_service_client: BlobServiceClient, container_name: str, path_csv: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Function that downloads a CSV from a container in an Azure storage account and\n",
    "    returns it as a pandas DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    blob_service_client : BlobServiceClient\n",
    "        BlobServiceClient for the storage account to target. Must be authenticated and\n",
    "        allowed to access and interact with containers\n",
    "    container_name : str\n",
    "        Name of the container to get a list of blobs from\n",
    "    path_csv : str\n",
    "        Path to the CSV file in the container (can be obtained by calling \n",
    "        get_file_keys_from_container)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The downloaded CSV file as a pandas DataFrame in memory\n",
    "    \"\"\"\n",
    "\n",
    "    # -- 1. Initiate blob client and download blob\n",
    "    blob_client = blob_service_client.get_blob_client(\n",
    "        container=container_name, blob=path_csv\n",
    "    )\n",
    "    downloaded_blob = blob_client.download_blob()\n",
    "\n",
    "    # -- 2. Read incoming stream as pandas DataFrame\n",
    "    df = pd.read_csv(StringIO(downloaded_blob.content_as_text()))\n",
    "\n",
    "    return df\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Pay special attention to what inputs this function needs and how it knows what file to load, since this will need to be used in the Function as well. If you are able to pass the path to the file during runtime when using a Function (e.g. in the parameters passed in a POST request), you can simply use that as a parameter of the function.\n",
    "\n",
    "Apart from the dataset, Great Expectations needs some additional parameters for operations down the line. These are an identifier for the batch being run and a name for the data asset. These can be the same, as long as they can be used to identify which dataset is being evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 2. Load data, generate asset name and batch identifier\n",
    "#\n",
    "# To generate a testing suite, a batch of data can be used to develop\n",
    "# validations. Accordingly, in the lines below custom logic is required to load\n",
    "# a test dataset as a pandas DataFrame in the df_batch argument\n",
    "#\n",
    "# To make the RuntimeBatchRequest complete, which is used by GE for the\n",
    "# validations, an asset_name and batch_identifier are required\n",
    "df_batch = load_data()  # Needs to be defined!\n",
    "batch_identifier = \"BATCH IDENTIFIER OR LOGIC TO GENERATE IT GOES HERE\"\n",
    "asset_name = \"ASSET NAME OR LOGIC TO GENERATE IT GOES HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate batch request, generate suite and start validator\n",
    "When you have succesfully written logic to load data, the loaded batch will be passed to a RuntimeBatchRequest below in order to start an expectation suite. Great Expectations requires data to be passed as a request when you want to use the context to generate things such as expectation suites and checkpoints. The RuntimeBatchRequest is used here, because we are loading data (with our own logic) at runtime and want to pass that to subsequent objects.\n",
    "\n",
    "More information on runtime batch requests can be found [here](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_configure_a_runtimedataconnector/).\n",
    "\n",
    "Using the RuntimeBatchRequest, two things are done next:\n",
    "1. Generating an expectation suite: this will serve as a collection of tests you will run for future datasets\n",
    "2. Generate a validator: this object will use the batch dataset loaded previously to start running expectations over and storing these in the suite\n",
    "\n",
    "As soon as the suite and validator are initiated, you can start writing expectations in the next cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 3. Generate batch request at runtime using loaded tile\n",
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=\"runtime_data\",\n",
    "    data_connector_name=\"runtime_data_connector\",\n",
    "    data_asset_name=asset_name,\n",
    "    runtime_parameters={\"batch_data\": df_batch},\n",
    "    batch_identifiers={\"batch_identifier\": batch_identifier,},\n",
    ")\n",
    "\n",
    "# -- 4. Generate expectation suite, start validator\n",
    "suite = context.create_expectation_suite(\n",
    "    test_config.expectations_suite_name,\n",
    "    overwrite_existing=True,  \n",
    ")\n",
    "\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=test_config.expectations_suite_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectations\n",
    "Using the validator object, expectations can be formulated below. Since Great Expectations comes with many expectations out of the box, [this page](https://greatexpectations.io/expectations) is generally a good place to start browsing through these. \n",
    "\n",
    "Predefined expectations can be used by calling them using the validator object and passing the required arguments. For example, to run an expectation on the number of rows in a dataframe, the following snippet can be used:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Get number of rows of current batch\n",
    "row_count = df_batch.shape[0]\n",
    "\n",
    "# Make expectation where the maximum deviation from the batch number of rows is 1%\n",
    "max_delta = 0.01\n",
    "validator.expect_table_row_count_to_be_between(\n",
    "    min_value=row_count * (1-max_delta), max_value=row_count * (1+max_delta))\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "If you want to develop custom expectations, more information can be found about there [here](https://docs.greatexpectations.io/docs/guides/expectations/creating_custom_expectations/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 5. Set expectations\n",
    "## PUT YOUR EXPECTATIONS BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize suite and create checkpoint\n",
    "After running all the expectations that you want to apply to the data, the cell below can be executed to save the set of expectations as a suite and couple it with a checkpoint. This checkpoint can be used in other scripts (lambda_function.py) by passing a new batch of data (as RuntimeBatchRequest) along with the checkpoint name to the `run_checkpoint` method of an initialized DataContext (which is the same as the `context` object initialized in this notebook). Such a call would look like:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "results = context.run_checkpoint(\n",
    "    checkpoint_name=\"CHECKPOINT_NAME\",\n",
    "    validations=[{\"batch_request\": batch_request}],\n",
    "    )\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE**: you should choose what kind of checkpoint you want to use below: one with or without automatic Data Docs updates\n",
    "\n",
    "When the code below is ran, Great Expectations automatically saves the expectation suite and checkpoint to S3 via the validator and context objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 6. Save suite\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "# -- 7. Create checkpoint\n",
    "#       Two options are provided here for creating a checkpoint: \n",
    "#       1. Use a SimpleCheckpoint, which contains an action to automatically update the\n",
    "#          Data Docs website whenever a validation is run\n",
    "#       2. Use checkpoint_without_datadocs_update, which generates the same\n",
    "#          SimpleCheckpoint but without an automatic Data Docs update action. This is\n",
    "#          useful if you run many validations (1000+) in parallel, since rendering the\n",
    "#          Data Docs website becomes very slow in that case          \n",
    "\n",
    "# -- 7.1 Create Simple checkpoint with automatic data docs updates (DEFAULT)\n",
    "checkpoint_config = {\n",
    "    \"name\": test_config.checkpoint_name,\n",
    "    \"config_version\": 3,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"expectation_suite_name\": test_config.expectations_suite_name,\n",
    "    \"run_name_template\": test_config.run_name_template,\n",
    "}\n",
    "\n",
    "# -- 7.2 Create checkpoint without automatic data docs update\n",
    "# checkpoint_config = checkpoint_without_datadocs_update(test_config)\n",
    "context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Data Docs website\n",
    "Next, the command below can be ran to build the Data Docs website on S3, which provides an interactive user interface in which you can browse through expectation suites and check validation results. More on Data Docs can be found [here](https://docs.greatexpectations.io/docs/reference/data_docs/)\n",
    "\n",
    "In general, if you generate the website once, new validations should automatically be loaded onto it. If the website start lagging behind, just rerun the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_site_output = context.build_data_docs()\n",
    "print_ge_site_link(ge_site_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "After you have run all of the steps above, instantiated a Data Docs website and can see your expectation suite there, you are ready to proceed with developing the logic for the Azure function in `functions/grater-expectations/function.py`, creating a Docker Image with that, uploading that to ACR and deploying it as an Azure function.\n",
    "\n",
    "Please refer to the README for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Jupyter server\n",
    "After running all commands above and generating an expectation suite, checkpoint and website, run the command below to stop the Jupyter server from running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"jupyter notebook stop\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c89e88f1ac255c8816e2c1f4efb25e90f69d64517a11691a0b94aad36d0a26a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
